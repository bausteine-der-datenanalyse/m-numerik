[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "m-numerik",
    "section": "",
    "text": "Preamble",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#voraussetzungen",
    "href": "index.html#voraussetzungen",
    "title": "m-numerik",
    "section": "Voraussetzungen",
    "text": "Voraussetzungen\n\nGrundlagen Python\nEinbinden von zusätzlichen Paketen\nPlotten mit Matplotlib",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#verwendete-pakete-und-datensätze",
    "href": "index.html#verwendete-pakete-und-datensätze",
    "title": "m-numerik",
    "section": "Verwendete Pakete und Datensätze",
    "text": "Verwendete Pakete und Datensätze\n\nPakete\n\nNumPy\nMatplotlib\n\n\n\nDatensätze",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#bearbeitungszeit",
    "href": "index.html#bearbeitungszeit",
    "title": "m-numerik",
    "section": "Bearbeitungszeit",
    "text": "Bearbeitungszeit\nGeschätzte Bearbeitungszeit: 2h",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#lernziele",
    "href": "index.html#lernziele",
    "title": "m-numerik",
    "section": "Lernziele",
    "text": "Lernziele\n\nWas ist Numerik\nNumerische Verfahren umsetzen\nNumerische Integration\nNumerische Differentiation",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "skript/intro_integrale.html",
    "href": "skript/intro_integrale.html",
    "title": "1  Integration",
    "section": "",
    "text": "1.0.1 Ober- und Untersumme\nDie Bildung von Integralen findet beispielsweise bei der Bestimmung von Flächeninhalten oder von Gesamtkräften Anwendung. Formal wird das bestimmte Integral \\(\\mathsf{I}\\) der Funktion \\(\\mathsf{f(x)}\\) auf dem Intervall \\(\\mathsf{x \\in [a,b]}\\) wie folgt dargestellt.\n\\[ \\mathsf{I = \\int_a^b f(x)\\ dx} \\]\nIm Allgemeinen kann das Integral nicht analytisch gelöst werden, da die Stammfunktion \\(\\mathsf{F(x)}\\) nicht leicht zu bestimmen ist. In solchen Fällen können numersiche Verfahren eingesetzt werden um den Integralwert zu approximieren. Die numerische Integration wird oft auch als numersiche Quadratur bezeichnet.\nDieses Kapitel bietet eine kurze Übersicht von numerischen Integrationsmethoden:\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nEine der grundlegendsten Arten Integrale von Funktionen zu bestimmen sind die Ober- und Untersumme. Sie nähern den Integralwert durch eine Abschätzung nach oben bzw. unten an. Mit einer steigenden Anzahl von Stützstellen, d.h. Positionen an welchen die Funktion ausgewertet wird, konvergieren beide Abschätzungen gegen den Integralwert.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "skript/intro_integrale.html#definition",
    "href": "skript/intro_integrale.html#definition",
    "title": "1  Integration",
    "section": "1.1 Definition",
    "text": "1.1 Definition\nFür die Bildung der Ober- und Untersumme, werden gleichmäßig verteilte Stützstellen auf dem Intervall \\(\\mathsf{[a,b]}\\) benötigt. Werden \\(\\mathsf{n+1}\\) Stützstellen gewählt, so gilt:\n\\[ a = x_0 &lt; x_1 &lt; \\cdots &lt; x_n = b \\]\nDer Abstand der Stützstellen beträgt \\(\\mathsf{\\Delta x = (b-a)/(n-1)}\\). Auf jedem der \\(\\mathsf{n}\\) Teilintervalle \\(\\mathsf{[x_{i-1}, x_{i}]}\\) wird nun der maximale bzw. minimale Wert der Funktion \\(\\mathsf{f(x)}\\) bestimmt und als \\(\\mathsf{O_i}\\) bzw. \\(\\mathsf{U_i}\\) definiert.\n\\[ \\mathsf{O_i = \\max\\left( f(x) | x \\in [x_{i-1}, x_{i}] \\right)} \\] \\[ \\mathsf{U_i = \\min\\left( f(x) | x \\in [x_{i-1}, x_{i}] \\right)} \\]\nDie gesuchte Approximation des Integrals ist die Summe der \\(\\mathsf{O_i}\\) bzw. \\(\\mathsf{U_i}\\) mal der Breite des Teilintervalls, hier \\(\\mathsf{\\Delta x}\\):\n\\[ \\sum_{i=1}^n \\Delta x U_i \\lesssim I \\lesssim \\sum_{i=1}^n \\Delta x O_i \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "skript/intro_integrale.html#beispiel",
    "href": "skript/intro_integrale.html#beispiel",
    "title": "1  Integration",
    "section": "1.2 Beispiel",
    "text": "1.2 Beispiel\nBeispielhaft soll folgendes Integral bestimmt werden\n\\[ \\mathsf{I = \\int_0^2\\sin(3x) + 2x \\ dx} \\]\n\ndef fkt(x):\n    return np.sin(3*x) + 2*x\n\n# Daten für die Visualisierung\nx = np.linspace(0, 2, 100)\ny = fkt(x)\n\n# Exakte Lösung\nI_exakt = (-1/3*np.cos(3*2) + 2**2) - (-1/3)\n\nAls erstes werden die Stützstellen gleichmäßig im Intervall \\(\\mathsf{[0,2]}\\) verteilt.\n\nn = 5\n\nxi = np.linspace(0, 2, n)\nyi = fkt(xi)\n\nDie beiden Summen benötigen die Extremwerte der zu integrierenden Funktion in den Teilintervallen. Diese werden mit Hilfe einer Funktionsauswertung auf dem Teilintervall bestimmt. Für die nachfolgende Visualisierung hat die Menge der Summen ebenfalls \\(\\mathsf{n}\\) Elemente.\n\noben = np.zeros(n)\nunten = np.zeros(n)\n\nfor i in range(len(oben)-1): \n    cx = np.linspace(xi[i], xi[i+1], 50)\n    cy = fkt(cx)\n    oben[i+1] = np.max(cy)\n    unten[i+1] = np.min(cy)\n\nDie ersten Elemente der beiden Summenlisten werden auf die ersten Funktionswerte gesetzt, dies dient nur der folgenden Darstellung.\n\noben[0] = yi[0]\nunten[0] = yi[0]\n\nVisualisierung der einzelnen Funktionen.\n\nplt.plot(x, y, label='Funktion')\nplt.scatter(xi, yi, label='Stützstellen', c='C3', zorder=3)\nplt.plot(xi, oben, drawstyle='steps-pre', label='Obersumme')\nplt.plot(xi, unten, drawstyle='steps-pre', label='Untersumme')\n\nplt.vlines(xi, ymin=unten, ymax=oben, color='C1', alpha=0.6)\nplt.vlines(xi, ymin=0, ymax=unten, color='C2', alpha=0.6)\n\nplt.xlabel('x')\nplt.ylabel('y')\n\nplt.grid()\nplt.legend();\n\n\n\n\n\n\n\n\nDas obige Verfahren kann nun in einer Funktion zusammengefasst werden, welche die Summen der beiden Folgen zurückgibt.\n\ndef ou_summe(n, a=0, b=2):\n    xi = np.linspace(a, b, n)\n    yi = fkt(xi)\n    dx = xi[1] - xi[0]\n    \n    sum_oben = 0\n    sum_unten = 0\n    \n    for i in range(n-1): \n        cx = np.linspace(xi[i], xi[i+1], 50)\n        cy = fkt(cx)\n        oben = np.max(cy)\n        unten = np.min(cy)\n        sum_oben += dx * oben\n        sum_unten += dx * unten\n    \n    return sum_oben, sum_unten\n\nFür eine systematische Untersuchung des Konvergenzverhaltens, wird die Integrationsfunktion für verschiedene Anzahlen von Stützstellen aufgerufen.\n\nn_max = 100\nns = np.arange(2, n_max, 1, dtype=int)\nos = np.zeros(len(ns))\nus = np.zeros(len(ns))\n\n\nfor i, n in enumerate(ns):\n    o, u = ou_summe(n)\n    os[i] = o\n    us[i] = u\n\nDie graphische Darstellung der beiden Summen zeigt eine kontinuierliche Annäherung dieser.\n\nplt.plot(ns, os, label='Obersumme')\nplt.plot(ns, us, label='Untersumme')\n\nplt.axhline(y=I_exakt, color='C3', alpha=0.3)\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Integralwert')\n\nplt.grid()\nplt.legend();\n\n\n\n\n\n\n\n\nDies wird insbesondere deutlich, wenn die Differenz der beiden Summen aufgetragen wird. Mit einer logarithmischen Darstellung kann die kontinuierliche Annäherung auch quantitativ abgelesen werden.\n\nplt.plot(ns, os-us)\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Differenz Ober- und Untersumme')\n\n# plt.xscale('log')\nplt.yscale('log')\n\nplt.grid();",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "skript/intro_integrale.html#interpolation",
    "href": "skript/intro_integrale.html#interpolation",
    "title": "1  Integration",
    "section": "1.3 Interpolation",
    "text": "1.3 Interpolation\nBei der Bildung der Ober- und Untersumme wurde die zu integrierende Funktion durch einen konstanten Wert in den Teilintervallen zwischen den Stützstellen angenähert. Eine genauere Berechnung des Integrals kann durch eine bessere Interpolation erfolgen. Dazu eignen sich Polynome, da diese leicht zu Integrieren sind.\n\n1.3.1 Trapezregel\nDie Trapezregel beruht auf der Annäherung der zu integrierenden Funktion durch Geraden, d.h. Polynome vom Grad 1, auf den Teilintervallen. Die Approximation des Integralwertes ergibt sich entsprechend aus den Flächeninhalten der so entstandenen Trapeze.\nWie im vorhergehenden Kapitel wird das Verfahren anhand folgender Funktion demonstriert\n\\[ \\mathsf{I = \\int_0^2\\sin(3x) + 2x \\ dx} \\]\n\ndef fkt(x):\n    return np.sin(3*x) + 2*x\n\n# Daten für die Visualisierung\nx = np.linspace(0, 2, 100)\ny = fkt(x)\n\n# Exakte Lösung\nI_exakt = (-1/3*np.cos(3*2) + 2**2) - (-1/3)\n\nBildung der Stützpunkte:\n\nn = 5\n\nxi = np.linspace(0, 2, n)\nyi = fkt(xi)\n\nZunächst erfolgt noch die Visualisierung des Verfahrens.\n\nplt.plot(x, y, label='Funktion')\nplt.scatter(xi, yi, label='Stützstellen', c='C3')\nplt.plot(xi, yi, label='Approximation', c='C1')\n\nplt.vlines(xi, ymin=0, ymax=yi, color='C1', alpha=0.3)\n\nplt.grid()\nplt.legend();\n\n\n\n\n\n\n\n\nDie Integration selbst kann mittels der Funktion scipy.integrate.trapezoid ausgeführt werden.\n\nres = scipy.integrate.trapezoid(yi, xi)\nprint(f\"Integralwert mit {n} Stützstellen: {res:.4f}\")\n\nIntegralwert mit 5 Stützstellen: 4.0107\n\n\nDer so ermittelte Wert nähert sich dem exakten Wert mit zunehmender Anzahl der Stützstellen.\n\nn_max = 50\nns = np.arange(2, n_max, 1, dtype=int)\ntr = np.zeros(len(ns))\n\nfor i, n in enumerate(ns):\n    xi = np.linspace(0, 2, n)\n    yi = fkt(xi)\n    tr[i] = scipy.integrate.trapezoid(yi, xi)\n\n\nplt.plot(ns, tr)\nplt.axhline(y=I_exakt, color='C3', alpha=0.3)\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Integralwert')\n\nplt.grid();\n\n\n\n\n\n\n\n\n\nplt.plot(ns, np.abs(tr-I_exakt))\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Differenz zum exakten Wert')\n\n# plt.xscale('log')\nplt.yscale('log')\n\nplt.grid();\n\n\n\n\n\n\n\n\n\n\n1.3.2 Simpsonregel\nDie Verwendung eines Polynoms vom zweiten Grad führt zur Simpsonregel. Hierzu wird die Funktion an einem Zwischenwert, mittig im Teilintervall, ausgewertet und zusammen mit den Werten an den Stützstellen zur Bestimmung der Polynomkoeffizienten verwendet.\nAnhand des obigen Beispiels wird die Simpsonregel visuell demonstriert.\n\nn = 5\n\nxi = np.linspace(0, 2, n)\nyi = fkt(xi)\n\n\nplt.plot(x, y, label='Funktion')\nplt.scatter(xi, yi, label='Stützstellen', c='C3')\n\n# Bestimmung und Plotten der Polynome\nfor i in range(n-1):\n    dx = xi[i+1] - xi[i]\n    cx = (xi[i] + xi[i+1]) / 2\n    cy = fkt(cx)\n\n    P = np.polyfit([xi[i], cx, xi[i+1]], [yi[i], cy, yi[i+1]], 2)\n    \n    Px = np.linspace(xi[i], xi[i+1], 20)\n    Py = np.polyval(P, Px)\n    \n    label=None\n    if i==0: \n        label='Approximation'\n    \n    plt.plot(Px, Py, color='C1', label=label)\n\nplt.vlines(xi, ymin=0, ymax=yi, color='C1', alpha=0.3)\n\nplt.grid()\nplt.legend();\n\n\n\n\n\n\n\n\nDie Simpsonregel ist bereits in der Funktion scipy.integrate.simpson implementiert. Im Folgenden wird nur die Differenz zur Trapezregel demonstriert.\n\nn_max = 50\nns = np.arange(3, n_max, 2, dtype=int)\nsi = np.zeros(len(ns))\ntr = np.zeros(len(ns))\n\nfor i, n in enumerate(ns):\n    xi = np.linspace(0, 2, n)\n    yi = fkt(xi)\n    si[i] = scipy.integrate.simpson(yi, xi)\n    tr[i] = scipy.integrate.trapezoid(yi, xi)\n\n\nplt.plot(ns, np.abs(tr-I_exakt), label='Trapezregel')\nplt.plot(ns, np.abs(si-I_exakt), label='Simpsonregel')\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Differenz zum exakten Wert')\n\n# plt.xscale('log')\nplt.yscale('log')\n\nplt.legend()\nplt.grid();",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "skript/intro_integrale.html#monte-carlo",
    "href": "skript/intro_integrale.html#monte-carlo",
    "title": "1  Integration",
    "section": "1.4 Monte-Carlo",
    "text": "1.4 Monte-Carlo\nEin ganz anderer Ansatz zur Integration wird mit dem Monte-Carlo-Ansatz verfolgt. Hierbei werden Zufallspunkte \\(\\mathsf{x_i}\\) innerhalb der gesuchten Integralbereichs generiert. Der Mittelwert der dazugehörigen Summe der Funktionswerte \\(\\mathsf{f(x_i)}\\) nähert das Integral an. Insbesondere für eine kleine Anzahl von Zufallswerten kann das Ergebnis deutlich vom exakten Wert abweichen. Der Vorteil des Verfahrens wird bei hochdimensionalen Integralen deutlich.\nFür \\(\\mathsf{n \\gg 1}\\) zufällige Stützstellen \\(\\mathsf{x_i \\in [a, b]}\\) gilt folgende Näherung\n\\[\\mathsf{I = \\int_a^b f(x)\\ dx \\approx \\frac{b-a}{n}\\sum_{i=1}^n f(x_i)} \\]\nFür das Beispiel aus den vorhergehenden Kapiteln gilt\n\ndef fkt(x):\n    return np.sin(3*x) + 2*x\n\n# Daten für die Visualisierung\nx = np.linspace(0, 2, 100)\ny = fkt(x)\n\n# Exakte Lösung\nI_exakt = (-1/3*np.cos(3*2) + 2**2) - (-1/3)\n\n\nn = 2000\nxi = np.random.random(n) * 2\nyi = fkt(xi)\nI = 2 * 1/n * np.sum(yi)\nprint(f\"Integralwert für {n} Stützstellen: {I:.4f}\")\n\nIntegralwert für 2000 Stützstellen: 4.0216\n\n\n\nn_max = 50000\ndn = 250\nns = np.arange(dn, n_max, dn, dtype=int)\nmc = np.zeros(len(ns))\n\nxi = np.zeros(n_max)\n\nfor i, n in enumerate(ns):\n    xi[n-dn:n] = np.random.random(dn) * 2\n    yi = fkt(xi[:n])\n    mc[i] = 2 * 1/n * np.sum(yi)\n\n\nplt.plot(ns, np.abs(mc-I_exakt))\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Differenz zum exakten Wert')\n\n# plt.xscale('log')\nplt.yscale('log')\n\nplt.grid();\n\n\n\n\n\n\n\n\nAlternativ kann auch das Flächenverhältnis zwischen der zu integrierenden Funktion und einer Referenzfläche \\(\\mathsf{A_r}\\) gebildet werden. Hierzu werden \\(\\mathsf{n}\\) Zufallszahlenpaare \\(\\mathsf{(x_i, y_i)}\\) generiert und gezählt wieviele davon in der gesuchten Fläche liegen. Die Annahme ist, dass sich beide Verhältnisse für große \\(\\mathsf{n}\\) annähern. Im einfachsten Fall, wenn \\(\\mathsf{f(x) \\ge 0}\\), gilt folgende Abschätzung\n\\[\\mathsf {I \\approx \\frac{A_r \\cdot \\left|\\left\\{y_i \\ |\\  y_i &lt; f(x_i)\\right\\}\\right|}{n}} \\]\nIm obigen Beispiel kann die Fläche \\(\\mathsf{[0, 2] \\times [0, 4] = 8}\\) als Referenzfläche verwendet werden.\n\nn = 2000\nxi = np.random.random(n) * 2\nyi = np.random.random(n) * 4\n\nz = np.sum(yi &lt; fkt(xi))\n\nI = z / n * 8\nprint(f\"Integralwert für {n} Stützstellen: {I}\")\n\nIntegralwert für 2000 Stützstellen: 3.984\n\n\n\nn_max = 50000\ndn = 250\nns = np.arange(dn, n_max, dn, dtype=int)\nmc = np.zeros(len(ns))\n\nxi = np.zeros(n_max)\nyi = np.zeros(n_max)\n\nfor i, n in enumerate(ns):\n    xi[n-dn:n] = np.random.random(dn) * 2\n    yi[n-dn:n] = np.random.random(dn) * 4\n    z = np.sum(yi[:n] &lt; fkt(xi[:n]))\n    mc[i] = z / n * 8\n\n\nplt.plot(ns, np.abs(mc-I_exakt))\n\nplt.xlabel('Anzahl der Stützstellen n')\nplt.ylabel('Differenz zum exakten Wert')\n\n# plt.xscale('log')\nplt.yscale('log')\n\nplt.grid();",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "skript/intro_ableitungen.html",
    "href": "skript/intro_ableitungen.html",
    "title": "2  Differentiation",
    "section": "",
    "text": "2.1 Taylor-Entwicklung\nDie numerische Bestimmung von Ableitungen wird hier anhand von zwei Ansätzen demonstriert. Zum Einen als Differenzenquotienten und zum Anderen über das Polynomfitting. Angewendet werden diese Verfahren z.B. beim Suchen von Extrema in Experimental- oder Simulationsdaten, beim Lösen von Differentialgleichungen oder bei Optimierungsverfahren.\nObwohl die analytische Bildung einer Ableitung oft viel einfacher ist als die Integration, ist dies in den oben genannten Fällen nicht direkt möglich. Gesucht ist hierbei immer die Ableitung \\(\\mathsf{f'(x)}\\) einer Funktion \\(\\mathsf{f(x)}\\) oder einer diskreten Punktmenge \\(\\mathsf{(x_i, y_i)}\\) an einer bestimmten Stelle \\(\\mathsf{x=x_0}\\) oder auf einem Intervall.\nDie Grundidee bei den hier vorgestellten Differenzenquotienten bzw. Differenzenformeln ist die Annäherung der abzuleitenden Funktion mit einer Taylor-Entwicklung an mehreren Stellen. Damit kann nach der gesuchte Ableitung an der entsprechenden Entwicklungsstelle aufgelöst werden.\nMittels der Taylor-Entwicklung kann jede beliebig oft stetig differenzierbare Funktion \\(\\mathsf{f(x)}\\) um einem Entwicklungspunkt \\(\\mathsf{x_0}\\) beliebig genau angenähert werden. Die funktionale Abhängigkeit bezieht sich nun auf die Variable \\(\\mathsf{h}\\), welche nur in direkter Umgebung um \\(\\mathsf{x_0}\\) betrachtet wird. Die Taylor-Entwicklung lautet:\n\\[ \\mathsf{f(x_0 + h) = \\sum_{i=0}^{\\infty}\\frac{1}{i!}f^{(i)}(x_0)\\cdot h^i} \\] \\[ \\mathsf{ = f(x_0) + f'(x_0)\\cdot h + \\frac{1}{2} f''(x_0)\\cdot h^2 + \\frac{1}{6}f'''(x_0)\\cdot h^3 + \\cdots} \\]\nDiese Entwicklung kann auch nur bis zu einer vorgegebenen Ordnung betrachtet werden. So nimmt die Entwicklung bis zur Ordnung \\(\\mathsf{ \\mathcal{O}(h^3)}\\) folgende Form an:\n\\[\\mathsf{ f(x_0 + h) = f(x_0) + f'(x_0)\\cdot h + \\frac{1}{2} f''(x_0)\\cdot h^2 + \\mathcal{O}(h^3)} \\]\nHierbei deutet das Landau-Symbol \\(\\mathsf{\\mathcal{O}}\\) die Ordnung an, welche die vernachlässigten Terme, hier ab \\(\\mathsf{h^3}\\), als Approximationsfehler zusammenfasst. Die Ordnung gibt an wie schnell bzw. mit welchem funktionalem Zusammenhang der Approximationsfehler gegen Null läuft für \\(\\mathsf{h \\rightarrow 0}\\).\nEine graphische Darstellung der ersten Elemente der Reihe verdeutlichen nochmals die Grundidee. Das folgende Beispiel entwickelt die Funktion\n\\[ \\mathsf{f(x) = \\sin(3x) + 2x} \\]\nam Punkt \\(\\mathsf{x_0=0.85}\\).\ndef fkt(x, p=0):\n    if p==0:\n        return np.sin(3*x) + 2*x\n    if p==1:\n        return 3*np.cos(3*x) + 2\n    if p==2:\n        return -9*np.sin(3*x)\n    if p==3:\n        return -27*np.cos(3*x)\n    return None\n\n# Daten für die Visualisierung\nx = np.linspace(0, 2, 100)\ny = fkt(x, p=0)\nx0 = 0.85\n\n# Taylor-Elemente\nte = []\nte.append(0*(x-x0) + fkt(x0, p=0))\nte.append((x-x0) * fkt(x0, p=1))\nte.append((x-x0)**2 * fkt(x0, p=2) * 1/2)\nte.append((x-x0)**3 * fkt(x0, p=3) * 1/6)\nplt.plot(x, y, color='Grey', lw=3, label=\"Funktion\")\nplt.plot(x, te[0], label=\"$\\mathsf{\\mathcal{O}(1)}$\")\nplt.plot(x, te[0] + te[1], label=\"$\\mathsf{\\mathcal{O}(h)}$\")\nplt.plot(x, te[0] + te[1] + te[2], label=\"$\\mathsf{\\mathcal{O}(h^2)}$\")\nplt.plot(x, te[0] + te[1] + te[2] + te[3], label=\"$\\mathsf{\\mathcal{O}(h^3)}$\")\n\nplt.vlines(x0, ymin=0, ymax=fkt(x0), color='Grey', ls='--', alpha=0.5)\n\nplt.ylim([0,4])\n\nplt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\nplt.grid()\nplt.xlabel('x')\nplt.ylabel('y');\n\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:4: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:5: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:4: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:5: SyntaxWarning: invalid escape sequence '\\m'\n/var/folders/p_/ks3trxjx0jd839_g4g0vm4nc0000gn/T/ipykernel_60998/2784086881.py:2: SyntaxWarning: invalid escape sequence '\\m'\n  plt.plot(x, te[0], label=\"$\\mathsf{\\mathcal{O}(1)}$\")\n/var/folders/p_/ks3trxjx0jd839_g4g0vm4nc0000gn/T/ipykernel_60998/2784086881.py:3: SyntaxWarning: invalid escape sequence '\\m'\n  plt.plot(x, te[0] + te[1], label=\"$\\mathsf{\\mathcal{O}(h)}$\")\n/var/folders/p_/ks3trxjx0jd839_g4g0vm4nc0000gn/T/ipykernel_60998/2784086881.py:4: SyntaxWarning: invalid escape sequence '\\m'\n  plt.plot(x, te[0] + te[1] + te[2], label=\"$\\mathsf{\\mathcal{O}(h^2)}$\")\n/var/folders/p_/ks3trxjx0jd839_g4g0vm4nc0000gn/T/ipykernel_60998/2784086881.py:5: SyntaxWarning: invalid escape sequence '\\m'\n  plt.plot(x, te[0] + te[1] + te[2] + te[3], label=\"$\\mathsf{\\mathcal{O}(h^3)}$\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Differentiation</span>"
    ]
  },
  {
    "objectID": "skript/intro_ableitungen.html#differenzenformeln",
    "href": "skript/intro_ableitungen.html#differenzenformeln",
    "title": "2  Differentiation",
    "section": "2.2 Differenzenformeln",
    "text": "2.2 Differenzenformeln\nIn diesem Abschnitt werden Berechnungsformeln für die Approximation von Ableitungen durch Bildung von Funktionswertdifferenzen vorgestellt. Diese beruhen alle auf der Taylor-Entwicklung und können für beliebige Ableitungen und Ordnungen formuliert werden. Die einfachsten davon werden hier vorgestellt.\n\n2.2.1 Erste Ableitung erster Ordnung\nDie einfachste Differenzenformel ergibt sich aus der Taylor-Reihe bis \\(\\mathsf{\\mathcal{O}(h^2)}\\). Hier kann die Reihe direkt nach der gesuchten Ableitung an der Stelle \\(\\mathsf{x_0}\\) umgeformt werden.\n\\[\\mathsf{f(x_0 + h) = f(x_0) + f'(x_0)h + \\mathcal{O}(h^2)} \\] \\[\\mathsf{\\Rightarrow \\quad f'(x_0) = \\frac{f(x_0 + h) - f(x_0)}{h} + \\mathcal{O}(h)} \\]\nDies ist die vorwärtsgerichtete Differenzformel erster Ordnung für die erste Ableitung. Erste Ordnung bedeutet hierbei, dass im Grenzwert \\(\\mathsf{h\\rightarrow 0}\\) der Approximationsfehler linear mit der Schrittweite abnimmt.\nNach dieser Formel muss die abzuleitende Funktion an zwei Stellen \\(\\mathsf{f(x_0)}\\) und \\(\\mathsf{f(x_0+h)}\\) ausgewertet werden, um die Ableitung numerisch zu bestimmen. Im Grenzwert für eine beliebig kleine Schrittweite, d.h. \\(\\mathsf{h \\rightarrow 0}\\), nähert sich dieser Quotient der exakten Ableitung an der Stelle \\(\\mathsf{x_0}\\) an.\nDas folgende Beispiel demonstriert die Näherung anhand der Funktion\n\\[ \\mathsf{f(x) = \\sin(3x) + 2x} \\]\nDie Ableitung wird an der Stelle \\(\\mathsf{x_0 = 0.85}\\) angenähert.\n\ndef fkt(x):\n    return np.sin(3*x) + 2*x\n\n# Daten für die Visualisierung\nx = np.linspace(0, 2, 100)\ny = fkt(x)\n\n# Exakte Lösung bei x=0.85\nfp_exakt = 3*np.cos(3*0.85) + 2\n\n\n# Entwicklungspunkt und Schrittweite\nh = 0.25\nx0 = 0.85\n\n# Auswertung an den beiden Stellen\nf0 = fkt(x0)\nfh = fkt(x0 + h)\n\n# Bestimmung der Ableitungsnäherung\nfp = (fh - f0) / h\n\n\nprint(f\"Die numerische Näherung der Ableitung an der Stelle {x0:.2f}:\")\nprint(f\"Näherung mit Schrittweite {h:.2f}: {fp:.2f}\")\nprint(f\"Exakter Wert: {fp_exakt:.2f}\")\n\nDie numerische Näherung der Ableitung an der Stelle 0.85:\nNäherung mit Schrittweite 0.25: -0.86\nExakter Wert: -0.49\n\n\nDie Methode kann auch graphisch dargestellt werden. Die gesuchte Steigung ist die Steigung der eingezeichneten Geraden.\n\nplt.plot(x, y, label=\"Funktion\")\nplt.scatter([x0], [f0], color='C3', label='Entwicklungspunkt', zorder=3)\nplt.scatter([x0+h], [fh], color='C4', label='Auswertepunkte', zorder=3)\n\nplt.vlines(x0, ymin=0, ymax=f0, color='C3', alpha=0.5)\n\nplt.plot(x, f0 + fp*(x-x0), label='Differenzenformel')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid()\nplt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left');\n\n\n\n\n\n\n\n\n\n\n2.2.2 Erste Ableitung zweiter Ordnung\nMit dem gleichen Ansatz kann auch eine Differenzenformel zweiter Ordnung gefunden werden. Dazu wird die Funktion an den Stellen \\(\\mathsf{x_0-h}\\) und \\(\\mathsf{x_0+h}\\) mit der Taylor-Reihe bis zur Ordnung \\(\\mathsf{\\mathcal{O}(h^3)}\\) approximiert.\n\\[\\mathsf{f(x_0+h) = f(x_0) + f'(x_0)\\cdot h + \\frac{1}{2}f''(x_0)\\cdot h^2 + \\mathcal{O}(h^3)} \\] \\[\\mathsf{f(x_0-h) = f(x_0) - f'(x_0)\\cdot h + \\frac{1}{2}f''(x_0)\\cdot h^2 + \\mathcal{O}(h^3)} \\]\nDie Differenz dieser beiden Gleichungen führt zu\n\\[\\mathsf{f(x_0+h) - f(x_0-h) = 2f'(x_0)\\cdot h + \\mathcal{O}(h^3)} \\]\nUnd die Umformung nach der gesuchten Ableitung an der Stelle \\(\\mathsf{x_0}\\) ergibt\n\\[\\mathsf{f'(x_0) = \\frac{f(x_0+h) - f(x_0-h)}{2h} + \\mathcal{O}(h^2)} \\]\nDies ist die zentrale Differenzenformel für die erste Ableitung zweiter Ordnung. Wie bei der vorwärtsgerichteten Formel muss hier die Funktion an zwei Stellen ausgewertet werden, jedoch nicht mehr am Entwicklungspunkt selbst. Durch diese Symmetrie bzgl. des Entwicklungspunkts ergibt sich ein besseres, hier quadratisches, Konvergenzverhalten.\n\n# Auswertung an den beiden Stellen\nfnh = fkt(x0 - h)\nfph = fkt(x0 + h)\n\n# Bestimmung der Ableitungsnäherung\nfp = (fph - fnh) / (2*h)\n\n\nprint(f\"Die numerische Näherung der Ableitung an der Stelle {x0:.2f}:\")\nprint(f\"Näherung mit Schrittweite {h:.2f}: {fp:.2f}\")\nprint(f\"Exakter Wert: {fp_exakt:.2f}\")\n\nDie numerische Näherung der Ableitung an der Stelle 0.85:\nNäherung mit Schrittweite 0.25: -0.26\nExakter Wert: -0.49\n\n\nDie Methode kann auch graphisch dargestellt werden. Die gesuchte Steigung ist die Steigung der eingezeichneten Geraden.\n\nplt.plot(x, y, label=\"Funktion\")\nplt.scatter([x0], [f0], color='C3', label='Entwicklungspunkt', zorder=3)\nplt.scatter([x0-h, x0+h], [fnh, fph], color='C4', label='Auswertepunkte', zorder=3)\n\nplt.vlines(x0, ymin=0, ymax=f0, color='C3', alpha=0.5)\n\nplt.plot(x, fnh + fp*(x-x0+h), label='Differenzenformel')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid()\nplt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left');",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Differentiation</span>"
    ]
  },
  {
    "objectID": "skript/intro_ableitungen.html#zweite-ableitung-zweiter-ordnung",
    "href": "skript/intro_ableitungen.html#zweite-ableitung-zweiter-ordnung",
    "title": "2  Differentiation",
    "section": "2.3 Zweite Ableitung zweiter Ordnung",
    "text": "2.3 Zweite Ableitung zweiter Ordnung\nMit dem gleichen Schema wie oben, kann auch die Differenzenformel für die zweite Ableitung bestimmt werden. Diese lautet\n\\[\\mathsf{f''(x_0) = \\frac{f(x_0-h) - 2f(x_0) + f(x_0+h)}{h^2} + \\mathcal{O}(h^2)}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Differentiation</span>"
    ]
  },
  {
    "objectID": "skript/intro_ableitungen.html#fehlerbetrachtung",
    "href": "skript/intro_ableitungen.html#fehlerbetrachtung",
    "title": "2  Differentiation",
    "section": "2.4 Fehlerbetrachtung",
    "text": "2.4 Fehlerbetrachtung\nIn diesem Abschnitt werden die Approximationsfehler, d.h. Fehler aus der Differenzenformeln, und Rundungsfehler, d.h. Fehler durch die endliche Genauigkeit der digitalen Darstellung von Zahlen, betrachtet.\n\n2.4.1 Approximationsfehler\nDie Ordnung des Verfahrens kann durch die Betrachtung des Fehlers, hier zum bekannten exakten Wert, bestimmt werden. Dazu wird die Schrittweite kontinuierlich verkleinert.\n\n\nCode\ndef fkt(x):\n    return np.sin(3*x) + 2*x\n\n# Daten für die Visualisierung\nx = np.linspace(0, 2, 100)\ny = fkt(x)\n\n# Exakte Lösung bei x=1\nfp_exakt = 3*np.cos(3*0.85) + 2\n\n\n\n\nCode\nx0 = 0.85\n\nhs = []\nfpfs = []\nfpcs = []\n\n\nh0 = 1\nfor i in range(18):\n    h = h0 / 2**i\n\n    f0 = fkt(x0)\n    fnh = fkt(x0 - h)\n    fph = fkt(x0 + h)\n\n    fpf = (fph - f0) / h\n    fpc = (fph - fnh) / (2*h)\n    \n    hs.append(h)\n    fpfs.append(fpf)\n    fpcs.append(fpc)\n\n\n\n\nCode\nplt.plot(hs, np.abs(fpfs - fp_exakt), label='vorwärts')\nplt.plot(hs, np.abs(fpcs - fp_exakt), label='zentral')\n\nplt.plot([1e-5, 1e-1], [1e-5, 1e-1], '--', color='grey', label='Hilfslinien')\nplt.plot([1e-5, 1e-1], [1e-10, 1e-2], '--', color='grey')\n\nplt.xlabel('Schrittweite h')\nplt.ylabel('Fehler')\n\nplt.xscale('log')\nplt.yscale('log')\n\nplt.legend()\nplt.grid();\n\n\n\n\n\n\n\n\n\nIn der logiarithmischen Darstellung beider Achsen werden Potenzfunktionen zu Graden mit dem Potenzgrad als Steigung. Das bedeutet, dass der Fehler im obigen Plot sich wie eine Potenzfunktion mit dem Grad eins bzw. zwei verhält. Die eingezeichneten Hilfslinien haben eine Steigung von eins bzw. zwei. Dies entspricht auch der Ordnung \\(\\mathsf{\\mathcal{O}(h)}\\) bzw. \\(\\mathsf{\\mathcal{O}(h^2)}\\) aus der Differenzenformel.\n\n\n2.4.2 Rundungsfehler\nWird nun die Schrittweiter noch weiter verkleinert, wirkt sich die Genauigkeit der Darstellung von Zahlen bzw. Rundungsfehler auf die Approximation aus.\n\n\nCode\nx0 = 0.85\n\nhs = []\nfpfs = []\nfpcs = []\n\n\nh0 = 1\nfor i in range(35):\n    h = h0 / 2**i\n\n    f0 = fkt(x0)\n    fnh = fkt(x0 - h)\n    fph = fkt(x0 + h)\n\n    fpf = (fph - f0) / h\n    fpc = (fph - fnh) / (2*h)\n    \n    hs.append(h)\n    fpfs.append(fpf)\n    fpcs.append(fpc)\n\n\n\n\nCode\nplt.plot(hs, np.abs(fpfs - fp_exakt), label='vorwärts')\nplt.plot(hs, np.abs(fpcs - fp_exakt), label='zentral')\n\nplt.plot([1e-5, 1e-1], [1e-5, 1e-1], '--', color='grey', label='Hilfslinien')\nplt.plot([1e-5, 1e-1], [1e-10, 1e-2], '--', color='grey')\n\nplt.xlabel('Schrittweite h')\nplt.ylabel('Fehler')\n\nplt.xscale('log')\nplt.yscale('log')\n\nplt.legend()\nplt.grid();\n\n\n\n\n\n\n\n\n\nWie bereits vorgestellt, können 64-Bit-Zahlen nur mit einer Genauigkeit von etwa \\(\\mathsf{\\epsilon\\approx10^{-16}}\\) dargestellt werden. Das bedeutet, dass z.B. die Differenz von zwei Zahlen nicht genauer als \\(\\mathsf{\\epsilon}\\) berechnet werden kann. Dies ist der sogenannte Rundungsfehler.\nIm konkreten Fall der Vorwärtsdifferenzenformel bedeutet dies:\n\\[ \\mathsf{f'(x_0) = \\frac{f(x_0 + h) - f(x_0)}{h} + \\mathcal{O}(h)} \\] \\[\\mathsf{\\overset{Rundungsfehler}{\\Rightarrow} \\frac{f(x_0 + h) - f(x_0) + \\mathcal{O}(\\epsilon)}{h} + \\mathcal{O}(h)} \\] \\[ \\mathsf{= \\frac{f(x_0 + h) - f(x_0)}{h} + \\mathcal{O}\\left(\\frac{\\epsilon}{h}\\right) + \\mathcal{O}(h)} \\]\nDamit macht eine Verkleinerung von \\(\\mathsf{h}\\) nur Sinn, solange der Rundungsfehler klein gegenüber \\(\\mathsf{h}\\) ist. Genauer:\n\\[\\mathsf{\\frac{\\epsilon}{h} \\le h }\\] \\[\\mathsf{\\Rightarrow \\quad h \\ge \\sqrt{\\epsilon}} \\]\nMit \\(\\mathsf{\\epsilon \\approx 10^{-16}}\\) ist für diese Differenzenformel ein \\(\\mathsf{h}\\) nur bis etwa \\(\\mathsf{10^{-8}}\\) angemessen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Differentiation</span>"
    ]
  }
]